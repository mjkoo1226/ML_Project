{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59160a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"spotify_songs.csv\")\n",
    "# df.dropna()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bda524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = df.copy()\n",
    "\n",
    "# genre_map = {\n",
    "#     \"pop\": 0,\n",
    "#     \"rap\": 1,\n",
    "#     \"rock\": 2,\n",
    "#     \"r&b\": 3,\n",
    "#     \"latin\": 4,\n",
    "#     \"edm\": 5\n",
    "# }\n",
    "\n",
    "# df_new[\"genre_int\"] = df_new[\"playlist_genre\"].map(genre_map)\n",
    "# df_new.to_csv(\"spotify_songs_with_genre_int.csv\", index=False)\n",
    "\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be26ae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "track_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_artist",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_popularity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "track_album_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_album_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "track_album_release_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_genre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "playlist_subgenre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "danceability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "energy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "key",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loudness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mode",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "speechiness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "acousticness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "instrumentalness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "liveness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "valence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tempo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "duration_ms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "genre_int",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7e52175d-1f3c-413e-9289-fba2541540a3",
       "rows": [
        [
         "0",
         "6f807x0ima9a1j3VPbc7VN",
         "I Don't Care (with Justin Bieber) - Loud Luxury Remix",
         "Ed Sheeran",
         "66",
         "2oCs0DGTsRO98Gh5ZSl2Cx",
         "I Don't Care (with Justin Bieber) [Loud Luxury Remix]",
         "2019-06-14",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.748",
         "0.916",
         "6",
         "-2.634",
         "1",
         "0.0583",
         "0.102",
         "0.0",
         "0.0653",
         "0.518",
         "122.036",
         "194754",
         "0"
        ],
        [
         "1",
         "0r7CVbZTWZgbTCYdfa2P31",
         "Memories - Dillon Francis Remix",
         "Maroon 5",
         "67",
         "63rPSO264uRjW1X5E6cWv6",
         "Memories (Dillon Francis Remix)",
         "2019-12-13",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.726",
         "0.815",
         "11",
         "-4.969",
         "1",
         "0.0373",
         "0.0724",
         "0.00421",
         "0.357",
         "0.693",
         "99.972",
         "162600",
         "0"
        ],
        [
         "2",
         "1z1Hg7Vb0AhHDiEmnDE79l",
         "All the Time - Don Diablo Remix",
         "Zara Larsson",
         "70",
         "1HoSmj2eLcsrR0vE9gThr4",
         "All the Time (Don Diablo Remix)",
         "2019-07-05",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.675",
         "0.931",
         "1",
         "-3.432",
         "0",
         "0.0742",
         "0.0794",
         "2.33e-05",
         "0.11",
         "0.613",
         "124.008",
         "176616",
         "0"
        ],
        [
         "3",
         "75FpbthrwQmzHlBJLuGdC7",
         "Call You Mine - Keanu Silva Remix",
         "The Chainsmokers",
         "60",
         "1nqYsOef1yKKuGOVchbsk6",
         "Call You Mine - The Remixes",
         "2019-07-19",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.718",
         "0.93",
         "7",
         "-3.778",
         "1",
         "0.102",
         "0.0287",
         "9.43e-06",
         "0.204",
         "0.277",
         "121.956",
         "169093",
         "0"
        ],
        [
         "4",
         "1e8PAfcKUYoKkxPhrHqw4x",
         "Someone You Loved - Future Humans Remix",
         "Lewis Capaldi",
         "69",
         "7m7vv9wlQ4i0LFuJiE2zsQ",
         "Someone You Loved (Future Humans Remix)",
         "2019-03-05",
         "Pop Remix",
         "37i9dQZF1DXcZDD7cfEKhW",
         "pop",
         "dance pop",
         "0.65",
         "0.833",
         "1",
         "-4.672",
         "1",
         "0.0359",
         "0.0803",
         "0.0",
         "0.0833",
         "0.725",
         "123.976",
         "189052",
         "0"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_genre</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>genre_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6f807x0ima9a1j3VPbc7VN</td>\n",
       "      <td>I Don't Care (with Justin Bieber) - Loud Luxur...</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>66</td>\n",
       "      <td>2oCs0DGTsRO98Gh5ZSl2Cx</td>\n",
       "      <td>I Don't Care (with Justin Bieber) [Loud Luxury...</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.518</td>\n",
       "      <td>122.036</td>\n",
       "      <td>194754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0r7CVbZTWZgbTCYdfa2P31</td>\n",
       "      <td>Memories - Dillon Francis Remix</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>67</td>\n",
       "      <td>63rPSO264uRjW1X5E6cWv6</td>\n",
       "      <td>Memories (Dillon Francis Remix)</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.693</td>\n",
       "      <td>99.972</td>\n",
       "      <td>162600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1z1Hg7Vb0AhHDiEmnDE79l</td>\n",
       "      <td>All the Time - Don Diablo Remix</td>\n",
       "      <td>Zara Larsson</td>\n",
       "      <td>70</td>\n",
       "      <td>1HoSmj2eLcsrR0vE9gThr4</td>\n",
       "      <td>All the Time (Don Diablo Remix)</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.613</td>\n",
       "      <td>124.008</td>\n",
       "      <td>176616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75FpbthrwQmzHlBJLuGdC7</td>\n",
       "      <td>Call You Mine - Keanu Silva Remix</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>60</td>\n",
       "      <td>1nqYsOef1yKKuGOVchbsk6</td>\n",
       "      <td>Call You Mine - The Remixes</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.277</td>\n",
       "      <td>121.956</td>\n",
       "      <td>169093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e8PAfcKUYoKkxPhrHqw4x</td>\n",
       "      <td>Someone You Loved - Future Humans Remix</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>69</td>\n",
       "      <td>7m7vv9wlQ4i0LFuJiE2zsQ</td>\n",
       "      <td>Someone You Loved (Future Humans Remix)</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.725</td>\n",
       "      <td>123.976</td>\n",
       "      <td>189052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                         track_name  \\\n",
       "0  6f807x0ima9a1j3VPbc7VN  I Don't Care (with Justin Bieber) - Loud Luxur...   \n",
       "1  0r7CVbZTWZgbTCYdfa2P31                    Memories - Dillon Francis Remix   \n",
       "2  1z1Hg7Vb0AhHDiEmnDE79l                    All the Time - Don Diablo Remix   \n",
       "3  75FpbthrwQmzHlBJLuGdC7                  Call You Mine - Keanu Silva Remix   \n",
       "4  1e8PAfcKUYoKkxPhrHqw4x            Someone You Loved - Future Humans Remix   \n",
       "\n",
       "       track_artist  track_popularity          track_album_id  \\\n",
       "0        Ed Sheeran                66  2oCs0DGTsRO98Gh5ZSl2Cx   \n",
       "1          Maroon 5                67  63rPSO264uRjW1X5E6cWv6   \n",
       "2      Zara Larsson                70  1HoSmj2eLcsrR0vE9gThr4   \n",
       "3  The Chainsmokers                60  1nqYsOef1yKKuGOVchbsk6   \n",
       "4     Lewis Capaldi                69  7m7vv9wlQ4i0LFuJiE2zsQ   \n",
       "\n",
       "                                    track_album_name track_album_release_date  \\\n",
       "0  I Don't Care (with Justin Bieber) [Loud Luxury...               2019-06-14   \n",
       "1                    Memories (Dillon Francis Remix)               2019-12-13   \n",
       "2                    All the Time (Don Diablo Remix)               2019-07-05   \n",
       "3                        Call You Mine - The Remixes               2019-07-19   \n",
       "4            Someone You Loved (Future Humans Remix)               2019-03-05   \n",
       "\n",
       "  playlist_name             playlist_id playlist_genre  ... loudness  mode  \\\n",
       "0     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -2.634     1   \n",
       "1     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -4.969     1   \n",
       "2     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -3.432     0   \n",
       "3     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -3.778     1   \n",
       "4     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   -4.672     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0583        0.1020          0.000000    0.0653    0.518  122.036   \n",
       "1       0.0373        0.0724          0.004210    0.3570    0.693   99.972   \n",
       "2       0.0742        0.0794          0.000023    0.1100    0.613  124.008   \n",
       "3       0.1020        0.0287          0.000009    0.2040    0.277  121.956   \n",
       "4       0.0359        0.0803          0.000000    0.0833    0.725  123.976   \n",
       "\n",
       "   duration_ms  genre_int  \n",
       "0       194754          0  \n",
       "1       162600          0  \n",
       "2       176616          0  \n",
       "3       169093          0  \n",
       "4       189052          0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FILE_PATH = \"datasets/spotify_songs_with_genre_int.csv\"\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "df = df.dropna()   \n",
    "\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b234ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"track_popularity\", \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\"]]\n",
    "y = df[[\"genre_int\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfaaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a788af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\base.py:1363: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4414496726054515"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ----- sklearn default Random Forest Classifier -----\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=6,\n",
    "                                 n_jobs=-1, random_state=42)\n",
    "\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2877dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5162174508908177"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ----- Random Forest Classifier with ADA Boost -----\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    RandomForestClassifier(n_estimators=500, max_leaf_nodes=6,\n",
    "                           n_jobs=-1, random_state=42),\n",
    "    n_estimators=30, \n",
    "    learning_rate=0.5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca111736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.5678391959798995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2665\n",
      "[LightGBM] [Info] Number of data points in the train set: 26266, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.780779\n",
      "[LightGBM] [Info] Start training from score -1.747013\n",
      "[LightGBM] [Info] Start training from score -1.903460\n",
      "[LightGBM] [Info] Start training from score -1.786671\n",
      "[LightGBM] [Info] Start training from score -1.851937\n",
      "[LightGBM] [Info] Start training from score -1.694465\n",
      "LightGBM Accuracy: 0.5670778133089691\n"
     ]
    }
   ],
   "source": [
    "## ----- Other Gradient Boost Classifiers -----\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "\n",
    "# LightGBM\n",
    "lgb = LGBMClassifier(n_estimators=250, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgb.predict(X_test)\n",
    "print(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c224c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Don't Care (with Justin Bieber) - Loud Luxury Remix\n",
      "'6f807x0ima9a1j3VPbc7VN'\n"
     ]
    }
   ],
   "source": [
    "import spotifyyy\n",
    "import pprint\n",
    "\n",
    "song_name = df.iloc[0][\"track_name\"]\n",
    "print(song_name)\n",
    "song_id = spotifyyy.search_track_id(song_name)\n",
    "\n",
    "pprint.pprint(song_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ae948f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1218: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogReg] Acc: 0.4709107523606457\n",
      "Macro-F1: 0.46109814330723214\n",
      "\n",
      "[MLP] Accuracy: 0.5522388059701493\n",
      "Macro-F1: 0.5406707480768338\n",
      "\n",
      "[MLP] Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.27      0.33      1079\n",
      "           1       0.57      0.66      0.61      1160\n",
      "           2       0.64      0.70      0.67      1040\n",
      "           3       0.45      0.49      0.47      1075\n",
      "           4       0.48      0.47      0.48       983\n",
      "           5       0.69      0.68      0.68      1229\n",
      "\n",
      "    accuracy                           0.55      6566\n",
      "   macro avg       0.54      0.55      0.54      6566\n",
      "weighted avg       0.54      0.55      0.54      6566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ----- DNN(Deep Neural Networks) with Softmax -----\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 1) 스케일링 (train에 fit → test에 transform)\n",
    "scaler = StandardScaler()\n",
    "X_train_t = scaler.fit_transform(X_train)\n",
    "X_test_t  = scaler.transform(X_test)\n",
    "\n",
    "# 2) 베이스라인: 로지스틱 (멀티노미얼 + class_weight로 불균형 완화)\n",
    "lr = LogisticRegression(\n",
    "    max_iter=2000, multi_class=\"multinomial\", class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "lr.fit(X_train_t, y_train)\n",
    "pred_lr = lr.predict(X_test_t)\n",
    "\n",
    "print(\"[LogReg] Acc:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"Macro-F1:\", f1_score(y_test, pred_lr, average=\"macro\"))\n",
    "\n",
    "# 3) DNN(MLPClassifier) + Softmax\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    batch_size=64,\n",
    "    learning_rate_init=0.005,\n",
    "    max_iter=50,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=5,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp.fit(X_train_t, y_train)\n",
    "pred_mlp = mlp.predict(X_test_t)\n",
    "\n",
    "print(\"\\n[MLP] Accuracy:\", accuracy_score(y_test, pred_mlp))\n",
    "print(\"Macro-F1:\", f1_score(y_test, pred_mlp, average=\"macro\"))\n",
    "\n",
    "print(\"\\n[MLP] Classification report:\\n\")\n",
    "print(classification_report(y_test, pred_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2693440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44304798,  0.15173166,  0.9414075 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.14016463, -0.74147692,  0.98143937, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.82072565,  0.22359528,  1.10153499, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.14980675,  0.36527933, -1.14024986, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 2.00940885,  0.365945  , -1.10021799, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.68112928,  0.36510413, -0.61983552, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "log1p = FunctionTransformer(np.log1p, validate=False)\n",
    "\n",
    "log_cols = [\"duration_ms\", \"tempo\"]\n",
    "std_cols = [\"track_popularity\", \"loudness\", \n",
    "            \"danceability\", \"energy\", \"speechiness\", \n",
    "            \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\"]\n",
    "cat_cols = [\"key\", \"mode\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"log\", Pipeline([(\"log1p\", log1p), (\"std\", StandardScaler())]), log_cols),\n",
    "        (\"std\", StandardScaler(), std_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_edit = preprocessor.fit_transform(X)\n",
    "\n",
    "X_edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78af691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_edit, X_test_edit, y_train, y_test = train_test_split(\n",
    "    X_edit, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c806e858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4552238805970149"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ----- sklearn default Random Forest Classifier -----\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=6,\n",
    "                                 n_jobs=-1, random_state=42)\n",
    "\n",
    "rnd_clf.fit(X_train_edit, y_train)\n",
    "\n",
    "y_pred_rf_edit = rnd_clf.predict(X_test_edit)\n",
    "\n",
    "accuracy_score(y_test, y_pred_rf_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10b43857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.5729515686871763\n"
     ]
    }
   ],
   "source": [
    "## ----- Other Gradient Boost Classifiers -----\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "xgb.fit(X_train_edit, y_train)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test_edit)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa5fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Minjun\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.592592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2680\n",
      "[LightGBM] [Info] Number of data points in the train set: 26262, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score -1.780175\n",
      "[LightGBM] [Info] Start training from score -1.745769\n",
      "[LightGBM] [Info] Start training from score -1.904330\n",
      "[LightGBM] [Info] Start training from score -1.796569\n",
      "[LightGBM] [Info] Start training from score -1.840207\n",
      "[LightGBM] [Info] Start training from score -1.696595\n",
      "LightGBM Accuracy: 0.5752360645750838\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LightGBM\n",
    "lgb = LGBMClassifier(n_estimators=400, learning_rate=0.05, max_depth=-1, random_state=42)\n",
    "lgb.fit(X_train_edit, y_train)\n",
    "\n",
    "y_pred_lgb = lgb.predict(X_test_edit)\n",
    "print(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d2191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.7223186\ttotal: 29.8ms\tremaining: 17.9s\n",
      "100:\tlearn: 1.0962444\ttotal: 10.5s\tremaining: 51.7s\n",
      "200:\tlearn: 1.0018878\ttotal: 27.4s\tremaining: 54.5s\n",
      "300:\tlearn: 0.9294604\ttotal: 39s\tremaining: 38.7s\n",
      "400:\tlearn: 0.8693523\ttotal: 56.1s\tremaining: 27.8s\n",
      "500:\tlearn: 0.8169605\ttotal: 1m 17s\tremaining: 15.3s\n",
      "599:\tlearn: 0.7686360\ttotal: 1m 49s\tremaining: 0us\n",
      "CatBoost Accuracy: 0.5834602497715504\n"
     ]
    }
   ],
   "source": [
    "## ----- Catboost Classifier with Edit -----\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# CatBoost\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=600,\n",
    "    learning_rate=0.1,\n",
    "    depth=7,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "cat.fit(X_train_edit, y_train)\n",
    "\n",
    "y_pred_cat = cat.predict(X_test_edit)\n",
    "print(\"CatBoost Accuracy:\", accuracy_score(y_test, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82ac3386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.7227330\ttotal: 868ms\tremaining: 8m 40s\n",
      "100:\tlearn: 1.0973674\ttotal: 36.4s\tremaining: 3m\n",
      "200:\tlearn: 0.9985954\ttotal: 1m 8s\tremaining: 2m 16s\n",
      "300:\tlearn: 0.9279742\ttotal: 1m 42s\tremaining: 1m 41s\n",
      "400:\tlearn: 0.8669023\ttotal: 2m 13s\tremaining: 1m 6s\n",
      "500:\tlearn: 0.8140464\ttotal: 2m 44s\tremaining: 32.5s\n",
      "599:\tlearn: 0.7675391\ttotal: 3m 19s\tremaining: 0us\n",
      "CatBoost Accuracy: 0.5852878464818764\n"
     ]
    }
   ],
   "source": [
    "## ----- Catboost Classifier -----\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# CatBoost\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=600,\n",
    "    learning_rate=0.1,\n",
    "    depth=7,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "cat.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cat = cat.predict(X_test)\n",
    "print(\"CatBoost Accuracy:\", accuracy_score(y_test, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2fb406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Minjun\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogReg] Acc: 0.4766981419433445\n",
      "Macro-F1: 0.4656958866322511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1105: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MLP] Accuracy: 0.54629911666159\n",
      "Macro-F1: 0.5378624132155858\n",
      "\n",
      "[MLP] Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.36      0.37      1079\n",
      "           1       0.58      0.62      0.60      1160\n",
      "           2       0.64      0.71      0.68      1040\n",
      "           3       0.47      0.46      0.47      1075\n",
      "           4       0.52      0.41      0.46       983\n",
      "           5       0.64      0.69      0.66      1229\n",
      "\n",
      "    accuracy                           0.55      6566\n",
      "   macro avg       0.54      0.54      0.54      6566\n",
      "weighted avg       0.54      0.55      0.54      6566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## ----- DNN(Deep Neural Networks) with Softmax -----\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 2) 베이스라인: 로지스틱 (멀티노미얼 + class_weight로 불균형 완화)\n",
    "lr = LogisticRegression(\n",
    "    max_iter=2000, multi_class=\"multinomial\", class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "lr.fit(X_train_edit, y_train)\n",
    "pred_lr = lr.predict(X_test_edit)\n",
    "\n",
    "print(\"[LogReg] Acc:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"Macro-F1:\", f1_score(y_test, pred_lr, average=\"macro\"))\n",
    "\n",
    "# 3) DNN(MLPClassifier) + Softmax\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    batch_size=128,\n",
    "    alpha=1e-3,\n",
    "    learning_rate_init=6e-5,\n",
    "    max_iter=50,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=5,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp.fit(X_train_edit, y_train)\n",
    "pred_mlp = mlp.predict(X_test_edit)\n",
    "\n",
    "print(\"\\n[MLP] Accuracy:\", accuracy_score(y_test, pred_mlp))\n",
    "print(\"Macro-F1:\", f1_score(y_test, pred_mlp, average=\"macro\"))\n",
    "\n",
    "print(\"\\n[MLP] Classification report:\\n\")\n",
    "print(classification_report(y_test, pred_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a646620",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25908\\435456437.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_edit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Minjun\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'unique'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c2337c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: [0 1 2 3 4 5] K= 6\n",
      "genre_int\n",
      "5    6043\n",
      "1    5743\n",
      "0    5507\n",
      "3    5431\n",
      "4    5153\n",
      "Name: count, dtype: int64\n",
      "chance≈ 0.167  | majority≈ 0.184\n",
      "LR acc: 0.4559853792263174  macro-F1: 0.44765421130698907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minjun\\Documents\\Study\\25-2\\기계학습(COSE362)\\ML Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 클래스 개수/분포\n",
    "import numpy as np, pandas as pd\n",
    "y = df[\"genre_int\"].astype(int)\n",
    "print(\"classes:\", np.unique(y), \"K=\", y.nunique())\n",
    "print(y.value_counts().head())\n",
    "\n",
    "# 찬스 레벨(= 무작위 정확도) & 최빈 클래스 정확도\n",
    "chance = 1 / y.nunique()\n",
    "major = y.value_counts().iloc[0] / len(y)\n",
    "print(\"chance≈\", round(chance,3), \" | majority≈\", round(major,3))\n",
    "\n",
    "# stratify 분할 (꼭!)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[[\"track_popularity\",\"danceability\",\"energy\",\"key\",\"loudness\",\"mode\",\n",
    "        \"speechiness\",\"acousticness\",\"instrumentalness\",\"liveness\",\"valence\",\"tempo\",\"duration_ms\"]].copy()\n",
    "y = df[\"genre_int\"].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 베이스라인: 로지스틱(멀티노미얼 + 불균형 보정)\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "log1p = FunctionTransformer(np.log1p, validate=False)\n",
    "pre = ColumnTransformer([\n",
    "    (\"log\",  Pipeline([(\"log1p\", log1p), (\"std\", StandardScaler())]), [\"tempo\",\"duration_ms\"]),\n",
    "    (\"std\",  StandardScaler(), [\"track_popularity\",\"loudness\",\"danceability\",\"energy\",\n",
    "                                \"speechiness\",\"acousticness\",\"instrumentalness\",\"liveness\",\"valence\"]),\n",
    "    (\"cat\",  OneHotEncoder(handle_unknown=\"ignore\"), [\"key\",\"mode\"])\n",
    "])\n",
    "\n",
    "clf_lr = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"lr\",  LogisticRegression(max_iter=2000, multi_class=\"multinomial\", class_weight=\"balanced\"))\n",
    "]).fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "pred_lr = clf_lr.predict(X_test)\n",
    "print(\"LR acc:\", accuracy_score(y_test, pred_lr), \" macro-F1:\", f1_score(y_test, pred_lr, average=\"macro\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
